"""
æ–‡ç« æ€»ç»“ç”Ÿæˆå™¨
ç”¨äºç”Ÿæˆæ¯æ—¥å’Œæ¯å‘¨çš„æ–‡ç« æ€»ç»“
"""
from datetime import datetime, timedelta
from typing import List, Dict, Any
from backend.app.db import DatabaseManager
from backend.app.db.models import Article, DailySummary
from backend.app.services.analyzer.ai_analyzer import AIAnalyzer
import logging

logger = logging.getLogger(__name__)


class SummaryGenerator:
    """æ–‡ç« æ€»ç»“ç”Ÿæˆå™¨"""

    def __init__(self, ai_analyzer: AIAnalyzer):
        self.ai_analyzer = ai_analyzer

    def generate_daily_summary(self, db: DatabaseManager, date: datetime = None) -> DailySummary:
        """
        ç”Ÿæˆæ¯æ—¥æ€»ç»“

        Args:
            db: æ•°æ®åº“ç®¡ç†å™¨
            date: æ€»ç»“æ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰ï¼Œä¼šè®¡ç®—è¯¥æ—¥æœŸå½“å¤©çš„00:00:00è‡³23:59:59

        Returns:
            DailySummaryå¯¹è±¡
        """
        if date is None:
            date = datetime.now()

        # è®¡ç®—è¯¥å¤©çš„èµ·å§‹å’Œç»“æŸæ—¶é—´
        start_date = date.replace(hour=0, minute=0, second=0, microsecond=0)
        end_date = date.replace(hour=23, minute=59, second=59, microsecond=999999)

        logger.info(f"ğŸ“ ç”Ÿæˆæ¯æ—¥æ€»ç»“: {start_date.strftime('%Y-%m-%d %H:%M:%S')} ~ {end_date.strftime('%Y-%m-%d %H:%M:%S')}")

        # ç›´æ¥åœ¨åŒä¸€ä¸ªsessionä¸­å¤„ç†æ‰€æœ‰é€»è¾‘
        return self._create_summary(db, start_date, end_date, "daily", date)

    def generate_weekly_summary(self, db: DatabaseManager, date: datetime = None) -> DailySummary:
        """
        ç”Ÿæˆæ¯å‘¨æ€»ç»“

        Args:
            db: æ•°æ®åº“ç®¡ç†å™¨
            date: æ€»ç»“æ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰ï¼Œä¼šè®¡ç®—è¯¥æ—¥æœŸæ‰€åœ¨è‡ªå®šä¹‰å‘¨çš„å‘¨å…­è‡³å‘¨äº”
            è‡ªå®šä¹‰å‘¨è§„åˆ™ï¼šå‘¨å…­ã€å‘¨æ—¥ã€å‘¨ä¸€åˆ°å‘¨äº”ï¼Œä¸ºä¸€ä¸ªæ€»ç»“å‘¨

        Returns:
            DailySummaryå¯¹è±¡
        """
        if date is None:
            date = datetime.now()

        # ä½¿ç”¨è‡ªå®šä¹‰å‘¨æ ‡å‡†è®¡ç®—è¯¥å‘¨çš„èµ·å§‹æ—¥æœŸï¼ˆå‘¨å…­ï¼‰å’Œç»“æŸæ—¥æœŸï¼ˆå‘¨äº”ï¼‰
        # è‡ªå®šä¹‰å‘¨ï¼šå‘¨å…­åˆ°å‘¨äº”ï¼Œweekday(): Monday=0, Sunday=6
        # éœ€è¦æ‰¾åˆ°è¯¥æ—¥æœŸæ‰€åœ¨å‘¨çš„å‘¨å…­ï¼ˆèµ·å§‹ï¼‰å’Œå‘¨äº”ï¼ˆç»“æŸï¼‰
        weekday = date.weekday()  # Monday=0, Tuesday=1, ..., Sunday=6
        
        # è®¡ç®—è·ç¦»ä¸Šå‘¨å…­çš„å¤©æ•°
        # å¦‚æœä»Šå¤©æ˜¯å‘¨å…­(5)ï¼Œåˆ™è·ç¦»ä¸Šå‘¨å…­æ˜¯0å¤©
        # å¦‚æœä»Šå¤©æ˜¯å‘¨æ—¥(6)ï¼Œåˆ™è·ç¦»ä¸Šå‘¨å…­æ˜¯1å¤©
        # å¦‚æœä»Šå¤©æ˜¯å‘¨ä¸€(0)ï¼Œåˆ™è·ç¦»ä¸Šå‘¨å…­æ˜¯2å¤©
        # å¦‚æœä»Šå¤©æ˜¯å‘¨äº”(4)ï¼Œåˆ™è·ç¦»ä¸Šå‘¨å…­æ˜¯6å¤©
        if weekday == 5:  # å‘¨å…­
            days_since_saturday = 0
        elif weekday == 6:  # å‘¨æ—¥
            days_since_saturday = 1
        else:  # å‘¨ä¸€åˆ°å‘¨äº”
            days_since_saturday = weekday + 2
        
        start_date = date - timedelta(days=days_since_saturday)
        start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0)
        
        # ç»“æŸæ—¥æœŸæ˜¯å‘¨äº”ï¼ˆèµ·å§‹æ—¥æœŸ+6å¤©ï¼‰
        end_date = start_date + timedelta(days=6)
        end_date = end_date.replace(hour=23, minute=59, second=59, microsecond=999999)

        logger.info(f"ğŸ“ ç”Ÿæˆæ¯å‘¨æ€»ç»“: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')}")

        # ä½¿ç”¨è¯¥å‘¨çš„å‘¨äº”ä½œä¸ºsummary_date
        summary_date = end_date

        # ç›´æ¥åœ¨åŒä¸€ä¸ªsessionä¸­å¤„ç†æ‰€æœ‰é€»è¾‘
        return self._create_summary(db, start_date, end_date, "weekly", summary_date)

    def _create_summary(
        self,
        db: DatabaseManager,
        start_date: datetime,
        end_date: datetime,
        summary_type: str,
        date: datetime
    ) -> DailySummary:
        """
        åˆ›å»ºæ€»ç»“

        Args:
            db: æ•°æ®åº“ç®¡ç†å™¨
            start_date: å¼€å§‹æ—¶é—´
            end_date: ç»“æŸæ—¶é—´
            summary_type: æ€»ç»“ç±»å‹ï¼ˆdaily/weeklyï¼‰
            date: æ€»ç»“æ—¥æœŸ

        Returns:
            DailySummaryå¯¹è±¡
        """
        start_time = datetime.now()

        # åœ¨åŒä¸€ä¸ªsessionä¸­æŸ¥è¯¢æ–‡ç« å¹¶æå–æ•°æ®
        with db.get_session() as session:
            # æŸ¥è¯¢å·²åˆ†æçš„æ–‡ç« ï¼ŒæŒ‰é‡è¦æ€§å’Œå‘å¸ƒæ—¶é—´æ’åº
            articles = session.query(Article).filter(
                Article.is_processed == True,
                Article.published_at >= start_date,
                Article.published_at <= end_date
            ).order_by(
                Article.importance.desc(),
                Article.published_at.desc()
            ).all()

            if not articles:
                logger.warning("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ–‡ç« ")
                return None

            # å‡†å¤‡æ–‡ç« æ•°æ®
            articles_data = []
            for article in articles:
                display_title = article.title_zh if article.title_zh else article.title
                articles_data.append({
                    "id": article.id,
                    "title": display_title,
                    "source": article.source,
                    "importance": article.importance,
                    "published_at": article.published_at,
                    "summary": article.summary,
                })

        # ç»Ÿè®¡ä¿¡æ¯
        high_count = sum(1 for a in articles_data if a.get("importance") == "high")
        medium_count = sum(1 for a in articles_data if a.get("importance") == "medium")

        logger.info(f"  æ–‡ç« æ€»æ•°: {len(articles_data)} (é«˜é‡è¦æ€§: {high_count}, ä¸­é‡è¦æ€§: {medium_count})")

        # è°ƒç”¨LLMç”Ÿæˆæ€»ç»“
        prompt = self._build_summary_prompt(articles_data, summary_type, start_date, end_date)
        
        # æ ¹æ®æ€»ç»“ç±»å‹è®¾ç½®ä¸åŒçš„ç³»ç»Ÿæç¤ºè¯å’Œå‚æ•°
        if summary_type == "weekly":
            # å‘¨æŠ¥ä½¿ç”¨ä¸“ä¸šçš„è¡Œä¸šåˆ†æå¸ˆè§’è‰²å’Œæ›´é«˜çš„å‚æ•°
            system_prompt = """ä½ æ˜¯ä¸€åèµ„æ·±çš„è¡Œä¸šåˆ†æå¸ˆå’Œé£å‘æ´å¯Ÿè€…ï¼Œæ‹¥æœ‰è¶…è¿‡15å¹´çš„ä»ä¸šç»éªŒã€‚ä½ ä¸ä»…å…³æ³¨æ–°é—»äº‹ä»¶çš„è¡¨é¢ï¼Œæ›´æ“…é•¿ä»çº·ç¹å¤æ‚çš„ä¿¡æ¯ä¸­ï¼Œç©¿é€è¡¨è±¡ï¼Œè¯†åˆ«å‡ºé‚£äº›çœŸæ­£èƒ½å¤Ÿå½±å“è¡Œä¸šæ ¼å±€çš„æ½œåœ¨å˜åŒ–ã€æ–°å…´è¶‹åŠ¿å’Œå…³é”®ä¿¡å·ã€‚ä½ çš„åˆ†æä»¥æ·±åˆ»ã€å‰ç»å’Œé«˜åº¦æ¦‚æ‹¬æ€§è‘—ç§°ï¼Œæ—¨åœ¨ä¸ºå†³ç­–è€…æä¾›é«˜ä»·å€¼çš„å‚è€ƒã€‚

è¯·ä½¿ç”¨Markdownæ ¼å¼è¾“å‡ºæ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€åˆ—è¡¨ã€åŠ ç²—ç­‰Markdownè¯­æ³•ã€‚"""
            temperature = 0.5  # å‘¨æŠ¥éœ€è¦æ›´å¤šåˆ›é€ æ€§åˆ†æ
            max_tokens = 4000  # å‘¨æŠ¥éœ€è¦æ›´è¯¦ç»†çš„åˆ†æ
        else:
            # æ—¥æŠ¥ä½¿ç”¨åŸæœ‰çš„ç³»ç»Ÿæç¤ºè¯
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIé¢†åŸŸæ–°é—»åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿ä»å¤§é‡æ–‡ç« ä¸­æç‚¼å…³é”®ä¿¡æ¯å’Œè¶‹åŠ¿ã€‚è¯·ä½¿ç”¨Markdownæ ¼å¼è¾“å‡ºæ‰€æœ‰å†…å®¹ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€åˆ—è¡¨ã€åŠ ç²—ç­‰Markdownè¯­æ³•ã€‚"
            temperature = 0.3
            max_tokens = 2000
        
        summary_content = self.ai_analyzer.client.chat.completions.create(
            model=self.ai_analyzer.model,
            messages=[
                {
                    "role": "system",
                    "content": system_prompt
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            temperature=temperature,
            max_tokens=max_tokens
        )
        summary_text = summary_content.choices[0].message.content

        # æå–å…³é”®ä¸»é¢˜
        key_topics = self._extract_topics(articles_data)

        # æ¨èé‡è¦æ–‡ç« 
        recommended_articles = self._select_recommended_articles(articles_data)

        # è®¡ç®—è€—æ—¶
        generation_time = (datetime.now() - start_time).total_seconds()

        # ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆå¦‚æœå·²å­˜åœ¨åˆ™æ›´æ–°ï¼Œå¦åˆ™åˆ›å»ºï¼‰
        with db.get_session() as session:
            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒç±»å‹å’Œæ—¥æœŸçš„æ€»ç»“
            # å¯¹äºdailyç±»å‹ï¼Œæ¯”è¾ƒæ—¥æœŸï¼ˆå¿½ç•¥æ—¶é—´éƒ¨åˆ†ï¼‰
            # å¯¹äºweeklyç±»å‹ï¼Œæ¯”è¾ƒsummary_dateæ‰€åœ¨çš„å‘¨
            existing_summary = None
            if summary_type == "daily":
                # æ¯æ—¥æ€»ç»“ï¼šæ¯”è¾ƒæ—¥æœŸï¼ˆåªæ¯”è¾ƒå¹´æœˆæ—¥ï¼‰
                date_only = date.replace(hour=0, minute=0, second=0, microsecond=0)
                existing_summary = session.query(DailySummary).filter(
                    DailySummary.summary_type == summary_type,
                    DailySummary.summary_date >= date_only,
                    DailySummary.summary_date < date_only + timedelta(days=1)
                ).first()
            else:
                # æ¯å‘¨æ€»ç»“ï¼šæ¯”è¾ƒsummary_dateæ‰€åœ¨çš„è‡ªå®šä¹‰å‘¨ï¼ˆå‘¨å…­åˆ°å‘¨äº”ï¼‰
                # è®¡ç®—summary_dateæ‰€åœ¨å‘¨çš„å‘¨å…­å’Œå‘¨äº”
                weekday = date.weekday()
                if weekday == 5:  # å‘¨å…­
                    days_since_saturday = 0
                elif weekday == 6:  # å‘¨æ—¥
                    days_since_saturday = 1
                else:  # å‘¨ä¸€åˆ°å‘¨äº”
                    days_since_saturday = weekday + 2
                
                week_start = date - timedelta(days=days_since_saturday)
                week_start = week_start.replace(hour=0, minute=0, second=0, microsecond=0)
                week_end = week_start + timedelta(days=7)
                
                existing_summary = session.query(DailySummary).filter(
                    DailySummary.summary_type == summary_type,
                    DailySummary.summary_date >= week_start,
                    DailySummary.summary_date < week_end
                ).first()
            
            if existing_summary:
                # æ›´æ–°ç°æœ‰æ€»ç»“
                existing_summary.start_date = start_date
                existing_summary.end_date = end_date
                existing_summary.total_articles = len(articles_data)
                existing_summary.high_importance_count = high_count
                existing_summary.medium_importance_count = medium_count
                existing_summary.summary_content = summary_text
                existing_summary.key_topics = key_topics
                existing_summary.recommended_articles = recommended_articles
                existing_summary.model_used = self.ai_analyzer.model
                existing_summary.generation_time = generation_time
                existing_summary.updated_at = datetime.now()
                session.flush()
                summary_id = existing_summary.id
                logger.info(f"âœ… æ€»ç»“å·²æ›´æ–° (ID: {summary_id})")
            else:
                # åˆ›å»ºæ–°æ€»ç»“
                summary = DailySummary(
                    summary_type=summary_type,
                    summary_date=date,
                    start_date=start_date,
                    end_date=end_date,
                    total_articles=len(articles_data),
                    high_importance_count=high_count,
                    medium_importance_count=medium_count,
                    summary_content=summary_text,
                    key_topics=key_topics,
                    recommended_articles=recommended_articles,
                    model_used=self.ai_analyzer.model,
                    generation_time=generation_time
                )
                session.add(summary)
                session.flush()
                summary_id = summary.id
                logger.info(f"âœ… æ€»ç»“å·²ä¿å­˜ (ID: {summary_id})")
            
        # åœ¨sessionå¤–åˆ›å»ºä¸€ä¸ªæ–°çš„å¯¹è±¡è¿”å›ï¼Œé¿å…detached instanceé—®é¢˜
        return DailySummary(
            id=summary_id,
            summary_type=summary_type,
            summary_date=date,
            start_date=start_date,
            end_date=end_date,
            total_articles=len(articles_data),
            high_importance_count=high_count,
            medium_importance_count=medium_count,
            summary_content=summary_text,
            key_topics=key_topics,
            recommended_articles=recommended_articles,
            model_used=self.ai_analyzer.model,
            generation_time=generation_time
        )

    def _build_summary_prompt(
        self, 
        articles_data: List[Dict[str, Any]], 
        summary_type: str,
        start_date: datetime,
        end_date: datetime
    ) -> str:
        """
        æ„å»ºæ€»ç»“æç¤ºè¯

        Args:
            articles_data: æ–‡ç« æ•°æ®åˆ—è¡¨
            summary_type: æ€»ç»“ç±»å‹ï¼ˆdaily/weeklyï¼‰
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ

        Returns:
            æç¤ºè¯å­—ç¬¦ä¸²
        """
        # æ ¹æ®æ—¥æœŸèŒƒå›´ç”Ÿæˆå…·ä½“çš„æ—¶é—´æè¿°
        if summary_type == "daily":
            # æ¯æ—¥æ€»ç»“ï¼šæ˜¾ç¤ºå…·ä½“æ—¥æœŸ
            time_str = start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
        else:
            # æ¯å‘¨æ€»ç»“ï¼šæ˜¾ç¤ºæ—¥æœŸèŒƒå›´
            time_str = f"{start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} è‡³ {end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}"
            date_range = f"{start_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} è‡³ {end_date.strftime('%Yå¹´%mæœˆ%dæ—¥')}"

        # é€‰æ‹©æœ€é‡è¦çš„æ–‡ç« ï¼ˆå‘¨æŠ¥ä½¿ç”¨æ›´å¤šæ–‡ç« ï¼Œæ—¥æŠ¥ä¿æŒåŸæ ·ï¼‰
        if summary_type == "weekly":
            important_articles = articles_data[:50]  # å‘¨æŠ¥ä½¿ç”¨æ›´å¤šæ–‡ç« è¿›è¡Œåˆ†æ
        else:
            important_articles = articles_data[:20]

        # æ„å»ºæ–‡ç« åˆ—è¡¨
        articles_str = ""
        for i, article in enumerate(important_articles, 1):
            importance_emoji = "ğŸ”´" if article.get("importance") == "high" else "ğŸŸ¡" if article.get("importance") == "medium" else "âšª"
            # å‘¨æŠ¥éœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯
            if summary_type == "weekly":
                articles_str += f"""
{i}. {importance_emoji} [{article.get('source', 'Unknown')}] {article.get('title', 'N/A')}
   å‘å¸ƒæ—¶é—´: {article.get('published_at', datetime.now()).strftime('%Y-%m-%d %H:%M')}
   æ‘˜è¦: {article.get('summary', '')[:300]}
"""
            else:
                articles_str += f"""
{i}. {importance_emoji} [{article.get('source', 'Unknown')}] {article.get('title', 'N/A')}
   å‘å¸ƒæ—¶é—´: {article.get('published_at', datetime.now()).strftime('%Y-%m-%d %H:%M')}
   æ‘˜è¦: {article.get('summary', '')[:200]}...
"""

        # æ ¹æ®ç±»å‹ç”Ÿæˆä¸åŒçš„æç¤ºè¯
        if summary_type == "weekly":
            # å‘¨æŠ¥ä½¿ç”¨ä¸“ä¸šçš„è¡Œä¸šé£å‘æ´å¯Ÿæç¤ºè¯
            prompt = f"""# ä»»åŠ¡ (Mission)

åŸºäºæˆ‘æœ¬å‘¨æä¾›çš„ï¼ˆäººå·¥æ™ºèƒ½/AIï¼‰è¡Œä¸šç›¸å…³æ–°é—»èµ„è®¯ï¼Œäº§å‡ºä¸€ä»½ä¸“ä¸šçš„ã€Šæœ¬å‘¨è¡Œä¸šé£å‘æ´å¯Ÿæ‘˜è¦ã€‹ã€‚ä½ çš„æŠ¥å‘Šéœ€è¦è¶…è¶Šç®€å•çš„ä¿¡æ¯ç½—åˆ—ï¼Œæ ¸å¿ƒåœ¨äº**æç‚¼è§‚ç‚¹ã€è§£è¯»è¶‹åŠ¿ã€å¹¶é¢„æµ‹å…¶æ½œåœ¨å½±å“**ã€‚

# å·¥ä½œæµç¨‹ (Workflow)

1. **ä¿¡æ¯æ¢³ç†ä¸èšåˆ**ï¼šé¦–å…ˆï¼Œå…¨é¢é˜…è¯»å¹¶ç†è§£æˆ‘æä¾›çš„æ‰€æœ‰æ–°é—»å†…å®¹ã€‚å°†ç›¸å…³è”çš„äº‹ä»¶ã€æ•°æ®å’Œè§‚ç‚¹è¿›è¡Œåˆ†ç±»èšåˆã€‚
2. **å…³é”®ä¸»é¢˜è¯†åˆ«**ï¼šä»èšåˆåçš„ä¿¡æ¯ä¸­ï¼Œè¯†åˆ«å‡ºæœ¬å‘¨åå¤å‡ºç°æˆ–æœ€é‡è¦çš„2-3ä¸ªæ ¸å¿ƒä¸»é¢˜æˆ–å…³é”®å˜é‡ã€‚è¿™äº›æ˜¯å˜åŒ–çš„æºå¤´ã€‚
3. **è¶‹åŠ¿æç‚¼ä¸å‘½å**ï¼šåŸºäºè¿™äº›æ ¸å¿ƒä¸»é¢˜ï¼Œæç‚¼å‡ºæœ¬å‘¨æœ€å€¼å¾—å…³æ³¨çš„è¡Œä¸šè¶‹åŠ¿ã€‚ä¸ºæ¯ä¸ªè¶‹åŠ¿èµ‹äºˆä¸€ä¸ªç²¾å‡†ä¸”æ¦‚æ‹¬æ€§å¼ºçš„æ ‡é¢˜ï¼ˆä¾‹å¦‚ï¼š"AIå¤§æ¨¡å‹åº”ç”¨åŠ é€Ÿè½åœ°"ã€"å¸‚åœºè½¬å‘è¿½æ±‚æ€§ä»·æ¯”æ¶ˆè´¹"ã€"ä¾›åº”é“¾åŒºåŸŸåŒ–è¶‹åŠ¿å‡¸æ˜¾"ç­‰ï¼‰ã€‚
4. **æ·±åº¦åˆ†æä¸è§£è¯»**ï¼š
   * **"å‘ç”Ÿäº†ä»€ä¹ˆï¼Ÿ"**ï¼šç®€è¦è¯´æ˜è¯¥è¶‹åŠ¿ç”±å“ªäº›å…·ä½“æ–°é—»äº‹ä»¶æ”¯æ’‘ã€‚
   * **"è¿™æ„å‘³ç€ä»€ä¹ˆï¼Ÿ"**ï¼šæ·±å…¥åˆ†æè¿™äº›äº‹ä»¶èƒŒååæ˜ å‡ºçš„è¡Œä¸šå˜åŒ–ã€‚æ˜¯æŠ€æœ¯çªç ´ï¼Ÿæ˜¯æ¶ˆè´¹è€…è¡Œä¸ºå˜è¿ï¼Ÿæ˜¯æ”¿ç­–é©±åŠ¨ï¼Ÿè¿˜æ˜¯èµ„æœ¬æµå‘çš„æ”¹å˜ï¼Ÿ
   * **"å°†å¸¦æ¥ä»€ä¹ˆå½±å“ï¼Ÿ"**ï¼šä»çŸ­æœŸå’Œä¸­é•¿æœŸä¸¤ä¸ªç»´åº¦ï¼Œé¢„æµ‹è¿™ä¸€è¶‹åŠ¿å¯èƒ½å¯¹è¡Œä¸šç”Ÿæ€ã€ç«äº‰æ ¼å±€ã€äº§ä¸šé“¾ä¸Šä¸‹æ¸¸ä»¥åŠç›¸å…³ä¼ä¸šå¸¦æ¥çš„æ½œåœ¨å½±å“ã€æœºé‡æˆ–æŒ‘æˆ˜ã€‚
5. **æ€»ç»“ä¸å±•æœ›**ï¼šåœ¨æŠ¥å‘Šçš„æœ€åï¼Œç”¨ä¸€æ®µè¯å¯¹æœ¬å‘¨çš„æ•´ä½“è¡Œä¸šåŠ¨æ€è¿›è¡Œæ€»ç»“ï¼Œå¹¶å¯¹æœªæ¥1-3ä¸ªæœˆçš„åŠ¨å‘ç»™å‡ºä¸€ä¸ªç®€è¦çš„å±•æœ›æˆ–éœ€è¦å…³æ³¨çš„ç„¦ç‚¹ã€‚

# è¾“å‡ºæ ¼å¼ (Output Format)

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ç»“æ„åŒ–æ ¼å¼è¾“å‡ºä½ çš„æŠ¥å‘Šï¼Œä»¥ç¡®ä¿ä¸“ä¸šæ€§å’Œå¯è¯»æ€§ï¼š

---

**ã€äººå·¥æ™ºèƒ½è¡Œä¸šé£å‘æ´å¯Ÿå‘¨æŠ¥ | {date_range}ã€‘**

**ä¸€ã€ æœ¬å‘¨æ ¸å¿ƒæ‘˜è¦ (Executive Summary)**
*   ï¼ˆç”¨2-3å¥è¯é«˜åº¦æ¦‚æ‹¬æœ¬å‘¨æœ€é‡è¦çš„è¡Œä¸šå˜åŒ–å’Œæ ¸å¿ƒè§‚ç‚¹ï¼Œè®©è¯»è€…èƒ½è¿…é€ŸæŠŠæ¡è¦ç‚¹ã€‚ï¼‰

**äºŒã€ æœ¬å‘¨å…³é”®è¶‹åŠ¿æ´å¯Ÿ (Key Trends Insight)**

*   **è¶‹åŠ¿ä¸€ï¼š[ä¸ºè¶‹åŠ¿ä¸€å‘½å]**
    *   **ç°è±¡æè¿°**ï¼šç”±æœ¬å‘¨çš„[æ–°é—»äº‹ä»¶A]ã€[æ•°æ®B]ç­‰å…±åŒæŒ‡å‘...
    *   **è¶‹åŠ¿è§£è¯»**ï¼šè¿™åæ˜ å‡ºè¡Œä¸šåœ¨[æŸä¸ªæ–¹é¢]æ­£åœ¨å‘ç”Ÿæ·±åˆ»è½¬å˜ï¼Œå…¶æ ¸å¿ƒé©±åŠ¨åŠ›æ˜¯...
    *   **æ½œåœ¨å½±å“ä¸æœºé‡**ï¼šçŸ­æœŸæ¥çœ‹ï¼Œè¿™å°†å¯¹[ç›¸å…³ä¼ä¸š/é¢†åŸŸ]å¸¦æ¥...æœºä¼š/æŒ‘æˆ˜ã€‚é•¿æœŸæ¥çœ‹ï¼Œæˆ‘ä»¬é¢„æµ‹...

*   **è¶‹åŠ¿äºŒï¼š[ä¸ºè¶‹åŠ¿äºŒå‘½å]**
    *   **ç°è±¡æè¿°**ï¼šæœ¬å‘¨[å…¬å¸Cçš„åŠ¨æ€]ä¸[æ”¿ç­–Dçš„å‡ºå°]...
    *   **è¶‹åŠ¿è§£è¯»**ï¼šè¿™æ ‡å¿—ç€å¸‚åœºç«äº‰çš„ç„¦ç‚¹æ­£ä»...è½¬å‘...ï¼ŒèƒŒåçš„é€»è¾‘æ˜¯...
    *   **æ½œåœ¨å½±å“ä¸æœºé‡**ï¼šè¿™å°†è¿«ä½¿ä¼ä¸šé‡æ–°æ€è€ƒå…¶...æˆ˜ç•¥ã€‚å¯¹äº[ç‰¹å®šç±»å‹çš„å…¬å¸]è€Œè¨€ï¼Œè¿™å¯èƒ½æ˜¯ä¸€ä¸ª...çš„çª—å£æœŸã€‚

*   **ï¼ˆå¯é€‰ï¼‰è¶‹åŠ¿ä¸‰ï¼š[ä¸ºè¶‹åŠ¿ä¸‰å‘½å]**
    *   ...

**ä¸‰ã€ æœªæ¥å±•æœ› (Future Outlook)**
*   ï¼ˆç»¼åˆæœ¬å‘¨è§‚å¯Ÿï¼Œæˆ‘ä»¬åˆ¤æ–­æœªæ¥å‡ å‘¨å†…ï¼Œè¡Œä¸šéœ€è¦å¯†åˆ‡å…³æ³¨...ã€‚ç‰¹åˆ«æ˜¯...æ–¹é¢çš„åŠ¨å‘ï¼Œå¯èƒ½ä¼šæˆä¸ºä¸‹ä¸€ä¸ªå¼•çˆ†ç‚¹ã€‚ï¼‰

---

# å…³é”®è¦æ±‚ (Key Requirements)

*   **æ‹’ç»ç½—åˆ—**ï¼šä¸è¦ç®€å•åœ°å¤è¿°æ–°é—»ï¼Œå¿…é¡»è¿›è¡Œæç‚¼å’Œå‡åã€‚
*   **è§‚ç‚¹é²œæ˜**ï¼šåœ¨åˆ†æå’Œè§£è¯»éƒ¨åˆ†ï¼Œè¦æ•¢äºæå‡ºä½ åŸºäºä¿¡æ¯çš„åˆ¤æ–­å’Œè§‚ç‚¹ã€‚
*   **é€»è¾‘æ¸…æ™°**ï¼šç¡®ä¿ç°è±¡ã€è§£è¯»å’Œå½±å“ä¹‹é—´çš„é€»è¾‘é“¾æ¡æ˜¯æ¸…æ™°ä¸”æœ‰è¯´æœåŠ›çš„ã€‚
*   **è¯­è¨€ä¸“ä¸š**ï¼šä½¿ç”¨ä¸“ä¸šã€ç²¾ç‚¼ã€å®¢è§‚çš„å•†ä¸šåˆ†æè¯­è¨€ã€‚

# æœ¬å‘¨æ–°é—»ç´ æ (Weekly News Input)

ä»¥ä¸‹æ˜¯æœ¬å‘¨æ”¶é›†åˆ°çš„æ‰€æœ‰æ–°é—»æ ‡é¢˜ã€æ‘˜è¦å’Œå…³é”®ä¿¡æ¯ï¼š

{articles_str}

è¯·åŸºäºä»¥ä¸Šæ–°é—»ç´ æï¼ŒæŒ‰ç…§ä¸Šè¿°æ ¼å¼å’Œè¦æ±‚ï¼Œç”Ÿæˆä¸“ä¸šçš„ã€Šäººå·¥æ™ºèƒ½è¡Œä¸šé£å‘æ´å¯Ÿå‘¨æŠ¥ã€‹ã€‚"""
        else:
            # æ—¥æŠ¥ä¿æŒåŸæœ‰æ ¼å¼
            prompt = f"""è¯·åŸºäº{time_str}æœŸé—´é‡‡é›†çš„ä»¥ä¸‹AIé¢†åŸŸæ–‡ç« ï¼Œç”Ÿæˆä¸€ä»½{time_str}çš„æ–°é—»æ€»ç»“ã€‚

æ–‡ç« åˆ—è¡¨ï¼š
{articles_str}

è¯·ä½¿ç”¨Markdownæ ¼å¼è¾“å‡ºæ€»ç»“ï¼ŒæŒ‰ä»¥ä¸‹æ ¼å¼ï¼š

# ğŸ“Š {time_str}AIæ–°é—»æ€»ç»“

## ğŸ”¥ é‡ç‚¹æ–‡ç« 
åˆ—å‡º3-5ç¯‡æœ€é‡è¦çš„æ–‡ç« ï¼Œæ¯ç¯‡æ–‡ç« æ ¼å¼å¦‚ä¸‹ï¼š
- **æ–‡ç« æ ‡é¢˜ï¼ˆæ¥æºï¼‰**ï¼šç›´æ¥æè¿°æ–‡ç« çš„æ ¸å¿ƒå†…å®¹å’Œé‡è¦æ€§ï¼Œä¸è¦ä½¿ç”¨"æ ¸å¿ƒå†…å®¹"ã€"ä¸ºä»€ä¹ˆé‡è¦"ã€"æ–‡ç« æ ‡é¢˜å’Œæ¥æº"ç­‰ä»»ä½•æ ‡ç­¾æˆ–å­æ ‡é¢˜ï¼Œç›´æ¥è¾“å‡ºå†…å®¹å³å¯ã€‚ä¾‹å¦‚ï¼š
  - **èƒ½æ–‡èƒ½æ­¦!æ™ºå…ƒé¦–ä¸ªæœºå™¨äººè‰ºäººå¤©å›¢äº®ç›¸æ¹–å—å«è§†è·¨å¹´æ¼”å”±ä¼šï¼ˆé‡å­ä½ï¼‰**
    æ™ºå…ƒæœºå™¨äººé¦–æ¬¡åœ¨å¤§å‹ç”µè§†èŠ‚ç›®ä¸­äº®ç›¸ï¼Œå±•ç¤ºäº†AIæœºå™¨äººåœ¨å¨±ä¹é¢†åŸŸçš„åº”ç”¨æ½œåŠ›ï¼Œæ ‡å¿—ç€æœºå™¨äººä»å·¥ä¸šåœºæ™¯å‘æ¶ˆè´¹åœºæ™¯çš„é‡è¦çªç ´ã€‚

## ğŸ“Œ é‡è¦è¶‹åŠ¿
ä»è¿™äº›æ–‡ç« ä¸­æ€»ç»“å‡º2-3ä¸ªé‡è¦è¶‹åŠ¿æˆ–çƒ­ç‚¹è¯é¢˜

## ğŸ¯ æ¨èé˜…è¯»
æ ¹æ®æ–‡ç« çš„å…³è”æ€§å’Œé‡è¦æ€§ï¼Œæ¨è5-10ç¯‡å€¼å¾—æ·±å…¥é˜…è¯»çš„æ–‡ç« 

**é‡è¦æç¤ºï¼šè¯·ç¡®ä¿è¾“å‡ºå†…å®¹ä½¿ç”¨æ ‡å‡†çš„Markdownæ ¼å¼ï¼ŒåŒ…æ‹¬æ ‡é¢˜ï¼ˆ#ã€##ï¼‰ã€åˆ—è¡¨ï¼ˆ-ã€*ï¼‰ã€åŠ ç²—ï¼ˆ**æ–‡æœ¬**ï¼‰ç­‰Markdownè¯­æ³•ã€‚è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒä¸“ä¸šã€ç®€æ´çš„é£æ ¼ã€‚"""

        return prompt

    def _extract_topics(self, articles_data: List[Dict[str, Any]]) -> List[str]:
        """
        ä»æ–‡ç« ä¸­æå–å…³é”®ä¸»é¢˜ï¼ˆä»æ‘˜è¦ä¸­æå–ï¼‰

        Args:
            articles_data: æ–‡ç« æ•°æ®åˆ—è¡¨

        Returns:
            ä¸»é¢˜åˆ—è¡¨ï¼ˆç©ºåˆ—è¡¨ï¼Œå› ä¸ºä¸å†ä»topicså­—æ®µæå–ï¼‰
        """
        # ä¸å†ä»topicså­—æ®µæå–ï¼Œè¿”å›ç©ºåˆ—è¡¨
        return []

    def _select_recommended_articles(self, articles_data: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        é€‰æ‹©æ¨èæ–‡ç« 

        Args:
            articles_data: æ–‡ç« æ•°æ®åˆ—è¡¨

        Returns:
            æ¨èæ–‡ç« åˆ—è¡¨
        """
        recommended = []

        # ä¼˜å…ˆé€‰æ‹©é«˜é‡è¦æ€§æ–‡ç« 
        high_importance = [a for a in articles_data if a.get("importance") == "high"]
        medium_importance = [a for a in articles_data if a.get("importance") == "medium"]

        # é€‰æ‹©æœ€å¤š10ç¯‡æ¨èæ–‡ç« 
        selected_articles = (high_importance + medium_importance)[:10]

        for article in selected_articles:
            reason = ""
            if article.get("importance") == "high":
                reason = "é«˜é‡è¦æ€§æ–‡ç« ï¼Œå€¼å¾—é‡ç‚¹å…³æ³¨"
            elif article.get("importance") == "medium":
                reason = "ä¸­ç­‰é‡è¦æ€§ï¼Œå»ºè®®é˜…è¯»"

            recommended.append({
                "id": article.get("id"),
                "title": article.get("title"),
                "source": article.get("source"),
                "importance": article.get("importance"),
                "reason": reason
            })

        return recommended
