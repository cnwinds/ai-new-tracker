"""
ç¤¾äº¤å¹³å°çƒ­å¸–æŠ¥å‘Šç”Ÿæˆå™¨
æ ¹æ®n8nå·¥ä½œæµé€»è¾‘å®ç°çƒ­ç‚¹å°æŠ¥ç”Ÿæˆ
"""
import logging
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional
from sqlalchemy.orm import Session

from backend.app.db.models import SocialMediaPost, SocialMediaReport

logger = logging.getLogger(__name__)


class SocialMediaReportGenerator:
    """ç¤¾äº¤å¹³å°çƒ­å¸–æŠ¥å‘Šç”Ÿæˆå™¨"""

    def __init__(self, ai_analyzer=None):
        """
        åˆå§‹åŒ–æŠ¥å‘Šç”Ÿæˆå™¨

        Args:
            ai_analyzer: AIåˆ†æå™¨å®ä¾‹(å¯é€‰)
        """
        self.ai_analyzer = ai_analyzer

    def generate_daily_report(
        self,
        db: Session,
        posts: List[SocialMediaPost],
        report_date: Optional[datetime] = None,
        youtube_enabled: bool = True,
        tiktok_enabled: bool = True,
        twitter_enabled: bool = True,
        reddit_enabled: bool = True
    ) -> Optional[SocialMediaReport]:
        """
        ç”ŸæˆAIçƒ­ç‚¹å°æŠ¥ï¼ˆåŸºäºä¼ å…¥çš„é‡‡é›†æ•°æ®ï¼‰

        Args:
            db: æ•°æ®åº“ä¼šè¯
            posts: é‡‡é›†åˆ°çš„å¸–å­åˆ—è¡¨ï¼ˆæœ¬æ¬¡é‡‡é›†çš„å®æ—¶æ•°æ®ï¼‰
            report_date: æŠ¥å‘Šæ—¥æœŸ(é»˜è®¤ä»Šå¤©)
            youtube_enabled: æ˜¯å¦å¯ç”¨YouTube
            tiktok_enabled: æ˜¯å¦å¯ç”¨TikTok
            twitter_enabled: æ˜¯å¦å¯ç”¨Twitter
            reddit_enabled: æ˜¯å¦å¯ç”¨Reddit

        Returns:
            ç”Ÿæˆçš„æŠ¥å‘Šå¯¹è±¡
        """
        try:
            if not report_date:
                report_date = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)

            if not posts:
                logger.warning(f"æ²¡æœ‰ä¼ å…¥é‡‡é›†æ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š")
                return None

            # æŒ‰å¹³å°åˆ†ç»„å¹¶å»é‡(ä½¿ç”¨post_idå»é‡,ä¿ç•™ç¬¬ä¸€ä¸ª)
            youtube_posts_map = {}
            tiktok_posts_map = {}
            twitter_posts_map = {}
            reddit_posts_map = {}

            for post in posts:
                if post.platform == "youtube" and youtube_enabled:
                    if post.post_id not in youtube_posts_map:
                        youtube_posts_map[post.post_id] = post
                elif post.platform == "tiktok" and tiktok_enabled:
                    if post.post_id not in tiktok_posts_map:
                        tiktok_posts_map[post.post_id] = post
                elif post.platform == "twitter" and twitter_enabled:
                    if post.post_id not in twitter_posts_map:
                        twitter_posts_map[post.post_id] = post
                elif post.platform == "reddit" and reddit_enabled:
                    if post.post_id not in reddit_posts_map:
                        reddit_posts_map[post.post_id] = post

            youtube_posts = list(youtube_posts_map.values())
            tiktok_posts = list(tiktok_posts_map.values())
            twitter_posts = list(twitter_posts_map.values())
            reddit_posts = list(reddit_posts_map.values())

            # æŒ‰çˆ†æ¬¾åˆ†æ•°æ’åº
            youtube_posts.sort(key=lambda x: x.viral_score or 0, reverse=True)
            tiktok_posts.sort(key=lambda x: x.viral_score or 0, reverse=True)
            twitter_posts.sort(key=lambda x: x.viral_score or 0, reverse=True)
            reddit_posts.sort(key=lambda x: x.viral_score or 0, reverse=True)

            # ä½¿ç”¨LLMç¿»è¯‘æ ‡é¢˜å’Œåˆ¤æ–­ä»·å€¼ï¼ˆå¼‚æ­¥å¤„ç†ï¼Œä¸é˜»å¡ï¼‰
            if self.ai_analyzer:
                youtube_posts = self._translate_posts(db, youtube_posts)
                tiktok_posts = self._translate_posts(db, tiktok_posts)
                reddit_posts = self._translate_posts(db, reddit_posts)
                # Twitter: å…ˆç¿»è¯‘,å†è¿‡æ»¤ä»·å€¼
                twitter_posts = self._translate_posts(db, twitter_posts)
                twitter_posts = self._filter_valuable_tweets(db, twitter_posts)

                # ä¿å­˜ç¿»è¯‘ç»“æœåˆ°æ•°æ®åº“ï¼ˆæ‰¹é‡æ›´æ–°å¯¹åº”çš„æ•°æ®åº“è®°å½•ï¼‰
                try:
                    self._save_translation_to_db(db, youtube_posts + tiktok_posts + reddit_posts + twitter_posts)
                    db.commit()
                    logger.debug("ä¿å­˜ç¿»è¯‘å’Œä»·å€¼åˆ¤æ–­ç»“æœåˆ°æ•°æ®åº“æˆåŠŸ")
                except Exception as e:
                    logger.warning(f"ä¿å­˜ç¿»è¯‘ç»“æœå¤±è´¥: {e}")
                    db.rollback()

            # ç”ŸæˆæŠ¥å‘Šå†…å®¹ï¼ˆæŒ‰ç…§n8nå·¥ä½œæµçš„"çƒ­ç‚¹å°æŠ¥"æ ¼å¼ï¼‰
            report_content = self._generate_hotspot_report(
                youtube_posts=youtube_posts[:20],  # æ¯ä¸ªå¹³å°æœ€å¤š20æ¡
                tiktok_posts=tiktok_posts[:20],
                twitter_posts=twitter_posts[:20],
                reddit_posts=reddit_posts[:20],
                report_date=report_date
            )

            # åˆ›å»ºAIçƒ­ç‚¹å°æŠ¥è®°å½•
            # total_countåº”è¯¥æ˜¯å„å¹³å°è¿‡æ»¤åæ•°é‡çš„æ€»å’Œï¼Œè€Œä¸æ˜¯åŸå§‹postsçš„é•¿åº¦
            total_count = len(youtube_posts) + len(tiktok_posts) + len(twitter_posts) + len(reddit_posts)
            report = SocialMediaReport(
                report_date=report_date,
                youtube_count=len(youtube_posts),
                tiktok_count=len(tiktok_posts),
                twitter_count=len(twitter_posts),
                reddit_count=len(reddit_posts),
                total_count=total_count,
                report_content=report_content,
                youtube_enabled=youtube_enabled,
                tiktok_enabled=tiktok_enabled,
                twitter_enabled=twitter_enabled,
                reddit_enabled=reddit_enabled
            )

            db.add(report)
            db.commit()
            db.refresh(report)

            return report

        except Exception as e:
            logger.error(f"ç”ŸæˆAIçƒ­ç‚¹å°æŠ¥å¤±è´¥: {e}")
            db.rollback()
            return None

    def _translate_posts(self, db: Session, posts: List[SocialMediaPost]) -> List[SocialMediaPost]:
        """
        ç¿»è¯‘å¸–å­æ ‡é¢˜ä¸ºä¸­æ–‡ï¼ˆä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ï¼‰

        Args:
            db: æ•°æ®åº“ä¼šè¯
            posts: å¸–å­åˆ—è¡¨

        Returns:
            ç¿»è¯‘åçš„å¸–å­åˆ—è¡¨
        """
        if not self.ai_analyzer:
            return posts

        translated_posts = []
        cache_hits = 0
        llm_calls = 0

        for post in posts:
            try:
                # å¦‚æœå†…å­˜ä¸­å·²ç»æœ‰ä¸­æ–‡æ ‡é¢˜ï¼ˆæ¥è‡ªAPIç«¯ç‚¹é¢„å¡«å……ï¼‰ï¼Œè·³è¿‡
                if post.title_zh:
                    cache_hits += 1
                    translated_posts.append(post)
                    continue

                # ä»æ•°æ®åº“æŸ¥è¯¢ç¿»è¯‘ç¼“å­˜
                cached_title = None
                if post.post_id:
                    cached_post = db.query(SocialMediaPost).filter(
                        SocialMediaPost.post_id == post.post_id,
                        SocialMediaPost.title_zh.isnot(None),
                        SocialMediaPost.title_zh != ''
                    ).first()
                    if cached_post:
                        cached_title = cached_post.title_zh

                if cached_title:
                    cache_hits += 1
                    post.title_zh = cached_title
                    translated_posts.append(post)
                    continue

                # ç¿»è¯‘æ ‡é¢˜
                llm_calls += 1
                title_zh = self._translate_title(post.title or post.content[:200] or "")
                if title_zh:
                    post.title_zh = title_zh
                translated_posts.append(post)
            except Exception as e:
                logger.warning(f"ç¿»è¯‘æ ‡é¢˜å¤±è´¥: {e}")
                translated_posts.append(post)

        if len(posts) > 0:
            logger.info(f"ç¿»è¯‘å®Œæˆ: æ€»æ•°={len(posts)}, ç¼“å­˜å‘½ä¸­={cache_hits}, LLMè°ƒç”¨={llm_calls}")

        return translated_posts

    def _save_translation_to_db(self, db: Session, posts: List[SocialMediaPost]):
        """
        å°†ä¸´æ—¶å¯¹è±¡ä¸­çš„ç¿»è¯‘å’Œä»·å€¼åˆ¤æ–­ç»“æœä¿å­˜åˆ°æ•°æ®åº“

        Args:
            db: æ•°æ®åº“ä¼šè¯
            posts: å¸–å­åˆ—è¡¨ï¼ˆå¯èƒ½æ˜¯ä¸´æ—¶å¯¹è±¡ï¼‰
        """
        # æŒ‰ post_id åˆ†ç»„ï¼Œæ‰¹é‡æŸ¥è¯¢å¯¹åº”çš„æ•°æ®åº“è®°å½•
        post_ids = [p.post_id for p in posts if p.post_id]
        if not post_ids:
            return

        # æ‰¹é‡æŸ¥è¯¢æ•°æ®åº“ä¸­çš„è®°å½•
        db_posts = db.query(SocialMediaPost).filter(
            SocialMediaPost.post_id.in_(post_ids)
        ).all()

        # åˆ›å»º post_id -> db_post çš„æ˜ å°„
        db_posts_map = {p.post_id: p for p in db_posts}

        updated_count = 0
        for temp_post in posts:
            if not temp_post.post_id or temp_post.post_id not in db_posts_map:
                continue

            db_post = db_posts_map[temp_post.post_id]

            # æ›´æ–°ç¿»è¯‘ç»“æœ
            if temp_post.title_zh and not db_post.title_zh:
                db_post.title_zh = temp_post.title_zh
                updated_count += 1

            # æ›´æ–°ä»·å€¼åˆ¤æ–­ç»“æœ
            if hasattr(temp_post, 'has_value') and temp_post.has_value is not None and db_post.has_value is None:
                db_post.has_value = temp_post.has_value
                updated_count += 1

        if updated_count > 0:
            logger.debug(f"ä¿å­˜ç¿»è¯‘å’Œä»·å€¼åˆ¤æ–­ç»“æœ: æ›´æ–°{updated_count}æ¡è®°å½•")

    def _translate_title(self, title: str) -> Optional[str]:
        """
        ä½¿ç”¨LLMç¿»è¯‘æ ‡é¢˜ä¸ºä¸­æ–‡

        Args:
            title: åŸæ ‡é¢˜

        Returns:
            ä¸­æ–‡æ ‡é¢˜
        """
        if not self.ai_analyzer or not title:
            return None

        try:
            prompt = f"""ä½ æ˜¯ä¸€åæ–°é—»ç¼–è¾‘ï¼Œä»»åŠ¡æ˜¯å°†ä¸åŒæ¥æºçš„æ ‡é¢˜ç¿»è¯‘æˆä¸­æ–‡ï¼Œè¦æ±‚ç®€æ´ã€å‡†ç¡®ã€æœ‰é€»è¾‘ã€‚è¯·ç¡®ä¿è¾“å‡ºå…¨æ˜¯ä¸­æ–‡ã€‚

æ ‡é¢˜ï¼š{title}

è‹¥æ ‡é¢˜å†…å®¹å¤§äºä¸‰å¥è¯ï¼Œåˆ™æ ¹æ®æ ‡é¢˜é‡Œæ‰€æœ‰çš„ä¿¡æ¯ç”Ÿæˆä¸€æ®µ60â€“80å­—çš„ä¸­æ–‡æ‘˜è¦ï¼Œéµå¾ªä»¥ä¸‹æ­¥éª¤å’Œæ ¼å¼ï¼š

#æ­¥éª¤
1. æå–ä¸»è¯­å’Œæ ¸å¿ƒåŠ¨ä½œï¼Œæ ¼å¼ä¸º"è°åšäº†ä»€ä¹ˆ"
2. æ¦‚æ‹¬ä¸»è¦åŠŸèƒ½æˆ–ç”¨é€”ï¼Œæ ¼å¼ä¸º"å®ç°ä»€ä¹ˆåŠŸèƒ½ï¼Œè¾¾åˆ°ä»€ä¹ˆæ•ˆæœ"
3. å¦‚æœ‰äº®ç‚¹æˆ–åˆ›æ–°ç‚¹ï¼Œè¯·åŠ ä»¥æ€»ç»“
4. å¼ºè°ƒä¸»è§‚æ„ä¹‰æˆ–å½±å“ï¼Œæ ¼å¼ä¸º"å¯¹ä»€ä¹ˆæœ‰é‡è¦æ„ä¹‰"

#è¾“å‡ºè¦æ±‚
- åªè¿”å›ç¿»è¯‘åçš„ä¸­æ–‡æ ‡é¢˜æˆ–æ‘˜è¦ï¼Œä¸è¦æ·»åŠ ä»»ä½•è¯´æ˜
- å¦‚æœæ ‡é¢˜è¾ƒçŸ­ï¼Œç›´æ¥ç¿»è¯‘ï¼›å¦‚æœè¾ƒé•¿ï¼Œç”Ÿæˆ60-80å­—æ‘˜è¦

ä¸­æ–‡æ ‡é¢˜ï¼š"""

            response = self.ai_analyzer.client.chat.completions.create(
                model=self.ai_analyzer.model,
                messages=[
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€åä¸“ä¸šçš„æ–°é—»ç¼–è¾‘ï¼Œæ“…é•¿å°†è‹±æ–‡æ ‡é¢˜ç¿»è¯‘æˆå‡†ç¡®ã€ç®€æ´çš„ä¸­æ–‡æ ‡é¢˜ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.3,
                max_tokens=200,
            )

            translated = response.choices[0].message.content.strip()
            # å»é™¤å¯èƒ½çš„å¼•å·
            translated = translated.strip('"').strip("'").strip()
            return translated

        except Exception as e:
            logger.warning(f"ç¿»è¯‘æ ‡é¢˜å¤±è´¥: {e}")
            return None

    def _filter_valuable_tweets(self, db: Session, posts: List[SocialMediaPost]) -> List[SocialMediaPost]:
        """
        è¿‡æ»¤æœ‰ä»·å€¼çš„Twitteræ¨æ–‡ï¼ˆæ ¹æ®n8nå·¥ä½œæµé€»è¾‘ï¼Œä½¿ç”¨ç¼“å­˜ä¼˜åŒ–ï¼‰

        Args:
            db: æ•°æ®åº“ä¼šè¯
            posts: æ¨æ–‡åˆ—è¡¨

        Returns:
            æœ‰ä»·å€¼çš„æ¨æ–‡åˆ—è¡¨
        """
        if not self.ai_analyzer:
            return posts

        valuable_posts = []
        cache_hits = 0
        llm_calls = 0
        error_count = 0

        for post in posts:
            try:
                # å¦‚æœå†…å­˜ä¸­å·²ç»åˆ¤æ–­è¿‡ä»·å€¼ï¼ˆæ¥è‡ªAPIç«¯ç‚¹é¢„å¡«å……ï¼‰ï¼Œä½¿ç”¨å·²æœ‰ç»“æœ
                if hasattr(post, 'has_value') and post.has_value is not None:
                    cache_hits += 1
                    if post.has_value:
                        valuable_posts.append(post)
                    continue

                # ä»æ•°æ®åº“æŸ¥è¯¢ä»·å€¼åˆ¤æ–­ç¼“å­˜
                cached_value = None
                if post.post_id:
                    cached_post = db.query(SocialMediaPost).filter(
                        SocialMediaPost.post_id == post.post_id,
                        SocialMediaPost.has_value.isnot(None)
                    ).first()
                    if cached_post:
                        cached_value = cached_post.has_value

                if cached_value is not None:
                    cache_hits += 1
                    post.has_value = cached_value
                    if post.has_value:
                        valuable_posts.append(post)
                    continue

                # ä½¿ç”¨LLMåˆ¤æ–­ä¿¡æ¯ä»·å€¼
                llm_calls += 1
                has_value = self._judge_tweet_value(post)
                post.has_value = has_value
                logger.debug(f"Twitteræ¨æ–‡ä»·å€¼åˆ¤æ–­: post_id={post.post_id}, has_value={has_value}, title={post.title[:50] if post.title else ''}")
                if has_value:
                    valuable_posts.append(post)
            except Exception as e:
                error_count += 1
                logger.warning(f"åˆ¤æ–­æ¨æ–‡ä»·å€¼å¤±è´¥: post_id={post.post_id if post.post_id else 'unknown'}, error={e}")
                # å‡ºé”™æ—¶é»˜è®¤ä¿ç•™
                valuable_posts.append(post)

        if len(posts) > 0:
            logger.info(f"Twitterä»·å€¼åˆ¤æ–­å®Œæˆ: æ€»æ•°={len(posts)}, ç¼“å­˜å‘½ä¸­={cache_hits}, LLMè°ƒç”¨={llm_calls}, é”™è¯¯={error_count}")

        return valuable_posts

    def _judge_tweet_value(self, post: SocialMediaPost) -> bool:
        """
        åˆ¤æ–­æ¨æ–‡æ˜¯å¦æœ‰ä¿¡æ¯ä»·å€¼

        Args:
            post: æ¨æ–‡å¯¹è±¡

        Returns:
            æ˜¯å¦æœ‰ä»·å€¼
        """
        if not self.ai_analyzer:
            return True

        try:
            prompt = f"""ä½ æ˜¯ä¸€åAIç§‘æŠ€æ–°é—»ç¼–è¾‘ï¼Œä»»åŠ¡æ˜¯åˆ¤æ–­æ¨æ–‡æ˜¯å¦å…·æœ‰AIç›¸å…³çš„ä¿¡æ¯ä»·å€¼ã€‚

è¾“å…¥ä¿¡æ¯ï¼š
æ ‡é¢˜ï¼š{post.title or post.content[:200] or ''}
æ¥æºï¼š{post.author_name or ''}
æ—¥æœŸï¼š{post.published_at.strftime('%Y-%m-%d') if post.published_at else ''}
é“¾æ¥ï¼š{post.post_url or ''}
æ¿å—ï¼šTwitterçƒ­ç‚¹

åˆ¤æ–­æ ‡å‡†ï¼š
- è‹¥å†…å®¹åŒ…å«AIäº§å“ã€æ¨¡å‹ã€ç ”ç©¶ã€è¶‹åŠ¿ã€è§‚ç‚¹ã€æ”¿ç­–ã€ç¤¾ä¼šå½±å“ç­‰ä¿¡æ¯ â†’ æœ‰ä¿¡æ¯ä»·å€¼ã€‚
- è‹¥ä»…ä¸ºå›¾ç‰‡ã€æƒ…ç»ªè¡¨è¾¾ã€æ— å…³å¨±ä¹ã€æ“¦è¾¹ã€é—²èŠæˆ–ä¸AIæ— å…³ â†’ æ— ä¿¡æ¯ä»·å€¼ã€‚

è¯·åªè¿”å›JSONæ ¼å¼ï¼š
{{
  "æœ‰ä¿¡æ¯ä»·å€¼": true/false,
  "ç†ç”±": "åˆ¤æ–­ç†ç”±"
}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

            # æ„å»ºè¯·æ±‚å‚æ•°
            request_params = {
                "model": self.ai_analyzer.model,
                "messages": [
                    {
                        "role": "system",
                        "content": "ä½ æ˜¯ä¸€åAIç§‘æŠ€æ–°é—»ç¼–è¾‘ï¼Œæ“…é•¿åˆ¤æ–­å†…å®¹çš„ä¿¡æ¯ä»·å€¼ã€‚åªè¿”å›JSONæ ¼å¼ã€‚"
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": 0.3,
                "max_tokens": 200,
            }
            
            # å¦‚æœæ¨¡å‹æ”¯æŒJSONæ¨¡å¼ï¼Œæ·»åŠ response_format
            try:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒJSONæ¨¡å¼ï¼ˆé€šå¸¸æ˜¯gpt-4oæˆ–æ›´æ–°çš„æ¨¡å‹ï¼‰
                if "gpt-4" in self.ai_analyzer.model.lower() or "o1" in self.ai_analyzer.model.lower():
                    request_params["response_format"] = {"type": "json_object"}
            except:
                pass
            
            response = self.ai_analyzer.client.chat.completions.create(**request_params)

            result_text = response.choices[0].message.content.strip()
            # å°è¯•è§£æJSON
            try:
                result = json.loads(result_text)
                has_value = result.get("æœ‰ä¿¡æ¯ä»·å€¼", result.get("has_value", True))
                logger.debug(f"AIåˆ¤æ–­ç»“æœ: {result_text[:200]}, has_value={has_value}")
                return bool(has_value)
            except json.JSONDecodeError:
                # å¦‚æœJSONè§£æå¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–
                logger.warning(f"JSONè§£æå¤±è´¥ï¼Œå°è¯•æ–‡æœ¬æå–: {result_text[:200]}")
                if "true" in result_text.lower() or "æœ‰ä¿¡æ¯ä»·å€¼" in result_text or "true" in result_text:
                    return True
                # å¦‚æœæ˜ç¡®è¯´falseï¼Œæ‰è¿”å›Falseï¼Œå¦åˆ™é»˜è®¤ä¿ç•™
                if "false" in result_text.lower() and "æ— ä¿¡æ¯ä»·å€¼" in result_text:
                    return False
                # é»˜è®¤ä¿ç•™ï¼Œé¿å…è¯¯è¿‡æ»¤
                logger.warning(f"æ— æ³•ç¡®å®šä»·å€¼ï¼Œé»˜è®¤ä¿ç•™æ¨æ–‡")
                return True

        except Exception as e:
            logger.warning(f"åˆ¤æ–­æ¨æ–‡ä»·å€¼å¤±è´¥: {e}, é»˜è®¤ä¿ç•™")
            # å‡ºé”™æ—¶é»˜è®¤ä¿ç•™
            return True

    def _generate_hotspot_report(
        self,
        youtube_posts: List[SocialMediaPost],
        tiktok_posts: List[SocialMediaPost],
        twitter_posts: List[SocialMediaPost],
        reddit_posts: List[SocialMediaPost],
        report_date: datetime
    ) -> str:
        """
        ç”Ÿæˆçƒ­ç‚¹å°æŠ¥ï¼ˆæŒ‰ç…§n8nå·¥ä½œæµæ ¼å¼ï¼‰

        Args:
            youtube_posts: YouTubeçƒ­å¸–åˆ—è¡¨
            tiktok_posts: TikTokçƒ­å¸–åˆ—è¡¨
            twitter_posts: Twitterçƒ­å¸–åˆ—è¡¨
            reddit_posts: Redditçƒ­å¸–åˆ—è¡¨
            report_date: æŠ¥å‘Šæ—¥æœŸ

        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Šå†…å®¹
        """
        date_str = report_date.strftime("%Y-%m-%d")
        md_lines = [f"# {date_str} AIçƒ­ç‚¹å°æŠ¥\n"]

        # YouTubeçƒ­ç‚¹
        if youtube_posts:
            md_lines.append("\nğŸ”¥ **YouTubeçƒ­ç‚¹**\n")

            # æŒ‰æ¥æºåˆ†ç»„ï¼ˆç±»ä¼¼n8nå·¥ä½œæµä¸­çš„"çŸ­è§†é¢‘"ç­‰åˆ†ç±»ï¼‰
            by_source = {}
            for post in youtube_posts:
                # æ ¹æ®n8nå·¥ä½œæµï¼Œæ¥æºå¯èƒ½æ˜¯"çŸ­è§†é¢‘"æˆ–å…¶ä»–åˆ†ç±»
                source = post.author_name or "çŸ­è§†é¢‘"
                if source not in by_source:
                    by_source[source] = []
                by_source[source].append(post)

            # éå†æ¯ä¸ªæ¥æº
            for source, posts in by_source.items():
                md_lines.append(f"\n**{source}**\n")
                for post in posts:
                    title = post.title_zh or post.title or post.content[:100] or "æ— æ ‡é¢˜"
                    md_lines.append(f"- {title}\n{post.post_url or ''}\n")

            md_lines.append("\n---\n\n")

        # Twitterçƒ­ç‚¹
        if twitter_posts:
            md_lines.append("\nğŸ”¥ **Twitterçƒ­ç‚¹**\n")
            for post in twitter_posts:
                title = post.title_zh or post.title or post.content[:200] or "æ— æ ‡é¢˜"
                md_lines.append(f"- {title}\n{post.post_url or ''}\n")
            md_lines.append("\n---\n\n")

        # Redditçƒ­ç‚¹
        if reddit_posts:
            md_lines.append("\nğŸ’¬ **Redditçƒ­ç‚¹**\n")
            # æŒ‰ç‰ˆå—åˆ†ç»„
            by_subreddit = {}
            for post in reddit_posts:
                subreddit = post.extra_data.get("subreddit", "Reddit") if post.extra_data else "Reddit"
                if subreddit not in by_subreddit:
                    by_subreddit[subreddit] = []
                by_subreddit[subreddit].append(post)

            # éå†æ¯ä¸ªç‰ˆå—
            for subreddit, posts in by_subreddit.items():
                md_lines.append(f"\n**r/{subreddit}**\n")
                for post in posts:
                    title = post.title_zh or post.title or post.content[:100] or "æ— æ ‡é¢˜"
                    md_lines.append(f"- {title}\n{post.post_url or ''}\n")

            md_lines.append("\n---\n\n")

        # TikTokçƒ­ç‚¹
        if tiktok_posts:
            md_lines.append("\nğŸµ **TikTokçƒ­ç‚¹**\n")
            for post in tiktok_posts:
                title = post.title_zh or post.title or post.content[:200] or "æ— æ ‡é¢˜"
                md_lines.append(f"- {title}\n{post.post_url or ''}\n")
            md_lines.append("\n---\n")

        return "".join(md_lines)

    def _generate_markdown_report(
        self,
        youtube_posts: List[SocialMediaPost],
        tiktok_posts: List[SocialMediaPost],
        twitter_posts: List[SocialMediaPost],
        report_date: datetime
    ) -> str:
        """
        ç”ŸæˆMarkdownæ ¼å¼çš„æŠ¥å‘Šï¼ˆä¿ç•™åŸæœ‰æ ¼å¼ä½œä¸ºå¤‡é€‰ï¼‰

        Args:
            youtube_posts: YouTubeçƒ­å¸–åˆ—è¡¨
            tiktok_posts: TikTokçƒ­å¸–åˆ—è¡¨
            twitter_posts: Twitterçƒ­å¸–åˆ—è¡¨
            report_date: æŠ¥å‘Šæ—¥æœŸ

        Returns:
            Markdownæ ¼å¼çš„æŠ¥å‘Šå†…å®¹
        """
        # ä½¿ç”¨æ–°çš„çƒ­ç‚¹å°æŠ¥æ ¼å¼
        return self._generate_hotspot_report(
            youtube_posts=youtube_posts,
            tiktok_posts=tiktok_posts,
            twitter_posts=twitter_posts,
            report_date=report_date
        )

    def _format_youtube_stats(self, post: SocialMediaPost) -> str:
        """æ ¼å¼åŒ–YouTubeç»Ÿè®¡ä¿¡æ¯"""
        parts = []
        if post.view_count:
            parts.append(f"æ’­æ”¾{self._format_number(post.view_count)}")
        if post.like_count:
            parts.append(f"ç‚¹èµ{self._format_number(post.like_count)}")
        if post.comment_count:
            parts.append(f"è¯„è®º{self._format_number(post.comment_count)}")
        return " | ".join(parts)

    def _format_tiktok_stats(self, post: SocialMediaPost) -> str:
        """æ ¼å¼åŒ–TikTokç»Ÿè®¡ä¿¡æ¯"""
        parts = []
        if post.view_count:
            parts.append(f"æ’­æ”¾{self._format_number(post.view_count)}")
        if post.like_count:
            parts.append(f"ç‚¹èµ{self._format_number(post.like_count)}")
        if post.comment_count:
            parts.append(f"è¯„è®º{self._format_number(post.comment_count)}")
        if post.viral_score:
            parts.append(f"çˆ†æ¬¾æŒ‡æ•°{post.viral_score}")
        return " | ".join(parts)

    def _format_twitter_stats(self, post: SocialMediaPost) -> str:
        """æ ¼å¼åŒ–Twitterç»Ÿè®¡ä¿¡æ¯"""
        parts = []
        if post.view_count:
            parts.append(f"è§‚çœ‹{self._format_number(post.view_count)}")
        if post.like_count:
            parts.append(f"ç‚¹èµ{self._format_number(post.like_count)}")
        if post.share_count:
            parts.append(f"è½¬å‘{self._format_number(post.share_count)}")
        if post.comment_count:
            parts.append(f"å›å¤{self._format_number(post.comment_count)}")
        if post.viral_score:
            parts.append(f"çƒ­åº¦{self._format_number(int(post.viral_score))}")
        return " | ".join(parts)

    def _format_number(self, num: int) -> str:
        """æ ¼å¼åŒ–æ•°å­—(æ·»åŠ å•ä½)"""
        if num >= 1000000:
            return f"{num/1000000:.1f}M"
        elif num >= 1000:
            return f"{num/1000:.1f}K"
        return str(num)
